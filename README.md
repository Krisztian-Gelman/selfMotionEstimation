# Self-Motion and Orientation Estimation for Aircraft

## Overview

This project focuses on **vision-based self-motion estimation** for **Unmanned Aerial Vehicles (UAVs)** using onboard camera imagery.  
It investigates and compares different **optical flow–based algorithms** for estimating the vehicle’s motion trajectory and orientation in 3D space.

The framework processes both **real flight recordings** (captured by forward- and downward-facing cameras) and **synthetic data** generated by simulators such as *Unreal Engine* or *MATLAB*.  
By integrating camera calibration, feature detection, optical flow tracking, and motion estimation, this project aims to enhance the **accuracy and reliability** of vision-aided navigation systems for UAVs.

---

## Main Objectives

- Implement and evaluate **optical flow–based motion estimation algorithms**:
  - Lucas–Kanade (sparse optical flow)
  - Farneback (dense optical flow)
- Provide a **modular and extensible software architecture** for visual motion analysis.
- Compare estimated motion trajectories with **measured (ground-truth) flight paths**.
- Support both **real and simulated datasets** through a unified processing pipeline.

---

## Project Structure

The project follows an **industry-standard modular architecture**, separating algorithmic, utility, and control layers for scalability and maintainability.

```bash
selfmotionestimation/
│
├── core/                        # Core algorithms and processing logic
│   ├── calibration/
│   │   ├── camera_calibration.py        # Camera calibration and parameter export
│   │   └── fast_calibrator.py           # Fast camera calibration, if config file dont exists
│   │
│   ├── config/
│   │   └── config_manager.py            # Config manager
│   │
│   ├── evaluation/
│   │   ├── visualizer.py                # Visualise estimated trajectory
│   │   └── comparator.py                # Comparison of measured and estimated data
│   │
│   └── processing/
│       ├── flow/
│       │   ├── feature_tracker.py   # Optical flow implementation
│       │   └── optical_flow_methods.py      # Enumeration of available flow algorithms
│       │
│       ├── frame/
│       │   └── frame_processor.py   # Frame processing
│       │
│       ├── input/
│       │   └── input_manager.py     # Data loader modul                
│       │
│       ├── motion/
│       │   └── motion_estimator.py  # Motion estimator modul
│       │
│       ├── output/ 
│       │   └── result_exporter.py   # Result data exporter modul    
│       │
│       ├── sequence/ 
│       │   └── sequence_controller.py # Sequence controller modul              
│       │
│       └── visual/ 
│           └── display_manager.py   # Display manager modul                
│
├── data/                        # Input, configuration, and calibration data
│   ├── calibration/                     # Checkerboard calibration images /Data received/
│   │   ├── orig_videos/                   # Original drone calibration videos
│   │   │   ├── down/                      # Down camera
│   │   │   └── front/                     # Front camera  
│   │   │
│   │   └── png_dump/                      # PNG images (png dumped drone video)
│   │       ├── down/                      # Down camera
│   │       └── front/                     # Front camera
│   │
│   ├── config/                          
│   │   └── camera_calibration_data.yaml # Stored calibration parameters
│   │
│   ├── log/                             # Logging
│   │   ├── output/                      # Log output dir
│   │   └── logger.py                    # Logger  
│   │
│   ├── results/                         # Results
│   │   ├── comparison/                  # Comparison results
│   │   │   ├── metrics/                 # Comparison metrics
│   │   │   └── plots/                   # Comparison plots
│   │   │
│   │   ├── plots/                       # Estimated trajectory plots
│   │   └── positions/                   # Estimated trajectory data
│   │
│   ├── sensor/                          # Sensor data from drone /Data received/
│   │   ├── codes/                       # Matlab scripts for drone data
│   │   └── sensor_data/                 # Drone sensor data
│   │
│   └── sequences/                       # Recorded flight image sequences /Data received/
│       ├── orig_videos/                   # Original drone flight videos
│       │   ├── down/                      # Down camera
│       │   └── front/                     # Front camera
│       │
│       └── png_dump/                      # PNG images (png dumped drone video)
│           ├── down/                      # Down camera
│           └── front/                     # Front camera
│
├── env/                         # Environment and deployment configuration (future use)
│   └── environment.yaml                     # Environment and dependency definitions
│
├── pipeline/                    # Control layer and entry points
│   └── pipeline.py                     # Pipeline orchestrator managing data flow
│
├── utils/                       # Supporting utilities and tools
│   └── png_dump.py                     # Converts videos or datasets into image sequences
│
├── start.py                     # Main entry script – starts the full pipeline
│
└── README.md
```

Each module can be executed and tested independently, ensuring clear separation between data handling, algorithmic logic, and runtime orchestration.

---

## Dependencies & Environment Setup

All dependencies are defined in the environment configuration file:
`data/env/environment.yaml`

---

## Test Datasets

The full set of **flight recordings**, including:
- downward- and forward-facing camera videos,
- and the corresponding **sensor logs** (GPS, IMU, attitude data),

is available at the following link:

**Dataset Download:**  
https://mega.nz/folder/UGJjwSSb#tyM8nbsu6u7jMXnnS7bI3Q

These datasets are used for:
- optical flow evaluation,  
- motion estimation benchmarking,  
- and comparison against ground-truth flight measurements.

All test sequences referenced in this project are included in this archive.

---

## Usage

1. **Camera Calibration**  
   If calibration parameters are not available, run  
   `python core/calibration/camera_calibration.py`  
   This generates `camera_calibration_data.yaml` under `data/config/`.

2. **Run Motion Estimation**  
   Launch the main pipeline from the root directory:  
   `python start.py`

3. **Data Output**  
   - Estimated motion trajectories are exported as CSV files.  
   - Visualization windows show optical flow tracking and estimated path evolution in real time.

---

## Research Context

This work was developed as part of a **B.Sc. thesis** in the field of **computer vision and UAV motion estimation**, conducted at  
**Pázmány Péter Catholic University (PPKE ITK)**, UAV Vision Lab.

The system integrates classical optical flow methods with modern feature tracking and pose estimation techniques.  
The results are compared against measured flight trajectories to evaluate algorithmic accuracy and robustness.

---

## Future Extensions

- Integration of **deep learning–based optical flow** (TV-L1, DeepFlow, RAFT, etc.)  
- Implementation of **visual odometry and SLAM** modules  
- Development of advanced visualization and analytics dashboards  
- Expansion of dataset management and benchmarking tools  

---

## Authors

Developed by **Krisztián Gelman**  
in collaboration with the **UAV Vision Lab**  
Faculty of Information Technology and Bionics  
*Pázmány Péter Catholic University (PPKE ITK)*

---

## License

This project is intended for **academic and research use only**.  
For inquiries or collaboration opportunities, please contact the UAV Vision Lab.

---

## Project Status

**Active development** – ongoing optimization, evaluation, and integration of new algorithms.
